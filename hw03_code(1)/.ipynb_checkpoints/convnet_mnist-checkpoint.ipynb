{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 636, HW3: ConvNet on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from types import SimpleNamespace\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset with labels encoded as one-hot vectors\n",
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "        self.epochs = 0\n",
    "\n",
    "    def shuffle(self):\n",
    "        perm = np.arange(self.data[0].shape[0])\n",
    "        np.random.shuffle(perm)\n",
    "        self.data = tuple(datai[perm] for datai in self.data)\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        start = self.index\n",
    "        end = self.index + batch_size\n",
    "        if end > self.data[0].shape[0]:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "            self.index, start = 0, 0\n",
    "            end = batch_size\n",
    "        self.index = end\n",
    "        return tuple(datai[start:end, ...] for datai in self.data)\n",
    "            \n",
    "def load_mnist():\n",
    "    def preprocess(data, labels, num_classes):\n",
    "        # flatten images\n",
    "        data = data.astype(np.float32)/255.0\n",
    "        data = np.reshape(data, [data.shape[0], -1])\n",
    "        # one hot encoding\n",
    "        num_labels = labels.shape[0]\n",
    "        index_offset = np.arange(num_labels) * num_classes\n",
    "        labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "        labels_one_hot.flat[index_offset + labels.ravel()] = 1\n",
    "        return data, labels_one_hot\n",
    "    train, test = tf.keras.datasets.mnist.load_data()\n",
    "    train = preprocess(train[0], train[1], 10)\n",
    "    test = preprocess(test[0], test[1], 10)\n",
    "    return SimpleNamespace(\n",
    "        train=Dataset(train), \n",
    "        test=Dataset(test))\n",
    "mnist = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= [28, 28]\n",
    "\n",
    "n_outputs= 10\n",
    "n_input_maps= 32 #''' HINT: The images are gray scale '''\n",
    "\n",
    "n_maps = 64\n",
    "filter_size = [5, 5]\n",
    "pool_size =   [2, 2]\n",
    "n_hidden = 256\n",
    "\n",
    "batch_size= 100 # play with different values for batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define the ConvNet\n",
    "# 1. Define the weights for the network\n",
    "\n",
    "# weights for first convolutional layer #\n",
    "''' HINT: The variables instantiation should look something similar to: '''\n",
    "# w1 = tf.Variable(\n",
    "#     tf.truncated_normal(\n",
    "#         shape=[filter_size_dim1, filter_size_dim2, #input_maps, #output_maps], \n",
    "#         stddev=0.1), \n",
    "#     name= 'w1')\n",
    "# b1 = tf.Variable(\n",
    "#     tf.truncated_normal(\n",
    "#         shape=[#output_maps], \n",
    "#         stddev=0.1), \n",
    "#     name= 'b1')\n",
    "\n",
    "w1 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[filter_size[0], filter_size[1], 1, n_input_maps], \n",
    "        stddev=0.1), \n",
    "    name= 'w1')\n",
    "b1 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[n_input_maps], \n",
    "        stddev=0.1), \n",
    "    name= 'b1')\n",
    "\n",
    "# # weights for second convolutional layer\n",
    "w2 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[filter_size[0], filter_size[1], n_input_maps, n_maps], \n",
    "        stddev=0.1), \n",
    "    name= 'w2')\n",
    "b2 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[n_maps], \n",
    "        stddev=0.1), \n",
    "    name= 'b2')\n",
    "\n",
    "# # weights for fully connected layer\n",
    "w3 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[4 * 4 * n_maps, n_hidden], \n",
    "        stddev=0.1), \n",
    "    name= 'w3')\n",
    "b3 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[n_hidden], \n",
    "        stddev=0.1), \n",
    "    name= 'b3')\n",
    "\n",
    "# # weights for final linear layer\n",
    "w4 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[n_hidden, n_outputs], \n",
    "        stddev=0.1), \n",
    "    name= 'w4')\n",
    "b4 = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "        shape=[n_outputs], \n",
    "        stddev=0.1), \n",
    "    name= 'b4')\n",
    "\n",
    "# Define place holders for feeding training and testing data\n",
    "inputs = tf.placeholder(tf.float32, shape=[None, 28, 28, 1]) \n",
    "labels = tf.placeholder(tf.float32, shape=[None, n_outputs])\n",
    "\n",
    "# Construct computation graph\n",
    "conv1 = tf.nn.conv2d(inputs, w1, strides=[1, 1, 1, 1], padding='VALID')\n",
    "h1 = tf.nn.relu(conv1 + b1)\n",
    "pool1 = tf.nn.max_pool(h1, ksize=  [1, pool_size[0], pool_size[1], 1],\n",
    "                           strides=[1, pool_size[0], pool_size[1], 1], \n",
    "                           padding='VALID')\n",
    "\n",
    "conv2 = tf.nn.conv2d(pool1, w2, strides=[1, 1, 1, 1], padding='VALID')\n",
    "h2 = tf.nn.relu(conv2 + b2)\n",
    "pool2 = tf.nn.max_pool(h2, ksize=  [1, pool_size[0], pool_size[1], 1],\n",
    "                           strides=[1, pool_size[0], pool_size[1], 1], \n",
    "                           padding='VALID')\n",
    "# # Reshape maps \n",
    "# ''' HINT: where does 4*4*64 comes from? use the architecture given in the assignment to figure this out !!! '''\n",
    "conv_out = tf.reshape(pool2, [-1, 4*4*64]) \n",
    "h3 = tf.nn.relu(tf.matmul(conv_out, w3) + b3)\n",
    "\n",
    "logits  = tf.matmul(h3, w4) + b4\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, \n",
    "    labels=labels)) \n",
    "\n",
    "# Optimizer.\n",
    "optimizer = tf.train.AdamOptimizer(1e-3).minimize(loss) #0.001\n",
    "  \n",
    "# Predictions for the training, validation, and test data.\n",
    "yp = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    if n_outputs == 1:\n",
    "        return (100.0 * np.sum(np.greater(predictions, 0.5) == np.greater(labels, 0.5))/ predictions.shape[0])\n",
    "    else:\n",
    "        return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "[[0.10684856 0.08560411 0.15441732 0.21688507 0.0616616  0.03327477\n",
      "  0.04870806 0.04557814 0.06783517 0.17918716]\n",
      " [0.10394779 0.05927498 0.12219556 0.30157614 0.04745375 0.03379099\n",
      "  0.04513608 0.05316518 0.05918248 0.17427707]\n",
      " [0.13358374 0.06638218 0.16057155 0.11550418 0.07145232 0.03890493\n",
      "  0.06557204 0.05877323 0.07700749 0.2122483 ]\n",
      " [0.1366721  0.0308898  0.08715612 0.18178909 0.03559621 0.02033671\n",
      "  0.13977991 0.07507768 0.07515566 0.2175467 ]\n",
      " [0.09684748 0.10802757 0.12474823 0.15067829 0.04225455 0.01847406\n",
      "  0.03269011 0.11095425 0.0542209  0.26110455]\n",
      " [0.12073594 0.06480496 0.14631149 0.09917089 0.0417116  0.02549588\n",
      "  0.08382072 0.16135697 0.05682968 0.19976194]\n",
      " [0.15667999 0.04592953 0.15509942 0.11549485 0.06148639 0.0245996\n",
      "  0.10042255 0.0631746  0.15156828 0.1255449 ]\n",
      " [0.16039687 0.08671439 0.19703023 0.14916633 0.02832805 0.03322188\n",
      "  0.0988918  0.05162815 0.08485497 0.10976724]\n",
      " [0.10527933 0.05624045 0.13726658 0.17496708 0.05388802 0.02137477\n",
      "  0.06833315 0.08650207 0.05718695 0.23896159]\n",
      " [0.14951688 0.06014205 0.16938928 0.14123954 0.05358646 0.03181652\n",
      "  0.09900039 0.04600013 0.06830644 0.18100233]\n",
      " [0.11487359 0.04419513 0.24682014 0.09115786 0.06190195 0.05457278\n",
      "  0.07837278 0.13586438 0.06400982 0.10823154]\n",
      " [0.12433713 0.05335744 0.11600892 0.23815538 0.05551501 0.03028508\n",
      "  0.08555572 0.03323881 0.03976881 0.22377768]\n",
      " [0.10284902 0.05412958 0.15152296 0.13428749 0.04687718 0.02242812\n",
      "  0.08642776 0.1612033  0.09378788 0.14648665]\n",
      " [0.13400578 0.08161702 0.08769314 0.10732137 0.05381543 0.04488035\n",
      "  0.04266133 0.05965027 0.11311637 0.27523887]\n",
      " [0.09627538 0.05631324 0.09611493 0.17939551 0.03802301 0.02860185\n",
      "  0.10101913 0.05297004 0.04661529 0.3046716 ]\n",
      " [0.1176932  0.07962195 0.17326684 0.16451114 0.07681205 0.03082149\n",
      "  0.04187898 0.05716828 0.06962609 0.18860003]\n",
      " [0.09200534 0.06397279 0.09187926 0.1305628  0.096573   0.04329656\n",
      "  0.13251555 0.08182845 0.06613803 0.2012282 ]\n",
      " [0.1070179  0.10500736 0.1262379  0.20140246 0.04229318 0.02820077\n",
      "  0.09341467 0.08571717 0.06891362 0.14179496]\n",
      " [0.10090969 0.06848121 0.08017251 0.17953105 0.04264734 0.02547952\n",
      "  0.07418599 0.09092811 0.11732224 0.22034243]\n",
      " [0.17614272 0.05563977 0.17645419 0.16963927 0.01592984 0.01545384\n",
      "  0.07949189 0.05531974 0.07398956 0.18193926]\n",
      " [0.08432814 0.05339953 0.11663238 0.17982206 0.03367266 0.04155666\n",
      "  0.12495401 0.09433883 0.07426977 0.19702601]\n",
      " [0.1954422  0.07135949 0.08217986 0.0793774  0.03824149 0.03236277\n",
      "  0.052458   0.05941876 0.10219568 0.28696442]\n",
      " [0.11078727 0.03877645 0.08376022 0.19985256 0.03048367 0.02360407\n",
      "  0.14780799 0.0932527  0.07918064 0.1924944 ]\n",
      " [0.13146941 0.06277835 0.07386966 0.13150354 0.05567971 0.04985431\n",
      "  0.10836481 0.06794406 0.09283672 0.22569937]\n",
      " [0.07829305 0.08384651 0.21353509 0.21366958 0.06204191 0.03077868\n",
      "  0.05312017 0.07100809 0.06484794 0.12885897]\n",
      " [0.14931023 0.08779001 0.06024436 0.16220291 0.05327969 0.02930096\n",
      "  0.05695665 0.11696673 0.08111916 0.20282939]\n",
      " [0.11276344 0.0925308  0.10881476 0.14168799 0.07924391 0.03349779\n",
      "  0.05198393 0.11512307 0.05338923 0.21096508]\n",
      " [0.11438527 0.09733838 0.16300833 0.18442106 0.07316476 0.02614049\n",
      "  0.06976682 0.04453306 0.06755605 0.15968576]\n",
      " [0.14360216 0.03351673 0.11137    0.2170898  0.05027997 0.03271584\n",
      "  0.09094787 0.04297988 0.08882065 0.18867706]\n",
      " [0.1153181  0.07557698 0.10326038 0.11380976 0.07178278 0.05917022\n",
      "  0.05269383 0.07696521 0.10104944 0.23037332]\n",
      " [0.13739577 0.06940708 0.10319106 0.15520065 0.04613934 0.02821845\n",
      "  0.04726418 0.12338925 0.09234329 0.19745095]\n",
      " [0.14302632 0.0702889  0.12150611 0.15663928 0.0333349  0.02317649\n",
      "  0.06448053 0.16675688 0.06191528 0.15887515]\n",
      " [0.14163055 0.08652832 0.1678833  0.14186233 0.06639246 0.04613816\n",
      "  0.053887   0.05363585 0.06562955 0.17641242]\n",
      " [0.16835906 0.05665164 0.08428473 0.29430863 0.01531505 0.02616436\n",
      "  0.05992457 0.08639523 0.09628588 0.11231086]\n",
      " [0.11800334 0.04598422 0.13143308 0.07517715 0.10266695 0.04028863\n",
      "  0.08166127 0.11478502 0.07785206 0.21214828]\n",
      " [0.16933672 0.04936889 0.09776723 0.15166692 0.05530931 0.06012119\n",
      "  0.07741087 0.07456404 0.08945988 0.174995  ]\n",
      " [0.13232434 0.02791999 0.14021657 0.21746022 0.03236537 0.03784144\n",
      "  0.07280496 0.03251377 0.12853663 0.17801665]\n",
      " [0.12468897 0.05566368 0.13839462 0.08379264 0.07274812 0.03602349\n",
      "  0.06917448 0.10206377 0.10241089 0.21503934]\n",
      " [0.0974599  0.04238942 0.13866313 0.18697177 0.06157162 0.03267165\n",
      "  0.06795098 0.08344864 0.06401896 0.22485399]\n",
      " [0.09224048 0.03605283 0.10512183 0.16490923 0.05510423 0.03733941\n",
      "  0.0929383  0.07608443 0.09090475 0.24930444]\n",
      " [0.16263998 0.07188034 0.12895195 0.13361377 0.0328715  0.03300074\n",
      "  0.10234476 0.06246835 0.1137387  0.1584899 ]\n",
      " [0.11227189 0.05706723 0.12826708 0.17942338 0.04899013 0.03225495\n",
      "  0.08394301 0.0705299  0.10829727 0.17895514]\n",
      " [0.13541089 0.05965531 0.11885488 0.13712962 0.09059619 0.05105163\n",
      "  0.05961473 0.09056772 0.11532677 0.14179233]\n",
      " [0.076122   0.06850114 0.10251443 0.2751802  0.05844729 0.03106554\n",
      "  0.06901249 0.04827739 0.06514982 0.20572974]\n",
      " [0.09637715 0.03791627 0.06805958 0.17447816 0.02656353 0.02900163\n",
      "  0.1247361  0.09764351 0.06289144 0.28233266]\n",
      " [0.15549982 0.06646438 0.14821236 0.18722512 0.04675839 0.04035742\n",
      "  0.06253325 0.04125623 0.04424408 0.20744899]\n",
      " [0.13833353 0.08819766 0.15003599 0.16953114 0.07591855 0.04120417\n",
      "  0.0486666  0.06072649 0.05904591 0.1683399 ]\n",
      " [0.11821251 0.03382174 0.1252107  0.07875712 0.07777899 0.04338739\n",
      "  0.08439805 0.0656969  0.14742586 0.22531079]\n",
      " [0.16538973 0.07938835 0.08989947 0.09894529 0.02610368 0.02657064\n",
      "  0.08329199 0.09206338 0.11942125 0.21892616]\n",
      " [0.15425926 0.03164674 0.1179685  0.2628174  0.05257521 0.02643026\n",
      "  0.09113542 0.04045581 0.10307296 0.11963844]\n",
      " [0.12827435 0.06491946 0.09972218 0.06485994 0.05726722 0.04179816\n",
      "  0.13006762 0.14968981 0.10802614 0.15537517]\n",
      " [0.1082178  0.09185655 0.14692777 0.23061341 0.04266024 0.03332666\n",
      "  0.06682692 0.08261149 0.05503336 0.14192583]\n",
      " [0.14361782 0.09908722 0.11042862 0.14778642 0.05180159 0.02467977\n",
      "  0.06552855 0.14021403 0.08616381 0.13069215]\n",
      " [0.16590995 0.05598063 0.13586833 0.08399677 0.0545128  0.01911398\n",
      "  0.10953798 0.13231388 0.10463109 0.13813469]\n",
      " [0.12325577 0.04195296 0.10091148 0.24248064 0.0278885  0.01630542\n",
      "  0.08933143 0.03350386 0.0998423  0.22452761]\n",
      " [0.16219334 0.09405886 0.08505378 0.08669304 0.03116739 0.0274576\n",
      "  0.05083054 0.03996272 0.09379733 0.3287854 ]\n",
      " [0.11541642 0.0469958  0.18062398 0.19202046 0.03154926 0.03768264\n",
      "  0.03572866 0.05874965 0.16668157 0.13455161]\n",
      " [0.14673118 0.0595931  0.08254901 0.10810866 0.03745477 0.02028712\n",
      "  0.06436706 0.1736958  0.08334058 0.22387274]\n",
      " [0.14587122 0.05136173 0.09153496 0.17026384 0.03646852 0.03634707\n",
      "  0.08309084 0.07736459 0.06955529 0.23814191]\n",
      " [0.10588491 0.05634111 0.14160642 0.14612484 0.04389758 0.05002044\n",
      "  0.0919609  0.04344939 0.14316753 0.17754693]\n",
      " [0.11803194 0.05173923 0.04927373 0.20445351 0.03738453 0.02042997\n",
      "  0.11627426 0.08240887 0.12480559 0.19519845]\n",
      " [0.13231455 0.06948905 0.10015854 0.16440558 0.04395358 0.02678493\n",
      "  0.09739251 0.05066796 0.08705926 0.22777407]\n",
      " [0.17931195 0.03735926 0.10327958 0.23122618 0.03695193 0.02535821\n",
      "  0.09320986 0.0488897  0.07557881 0.16883445]\n",
      " [0.10946471 0.04073216 0.10896225 0.18438019 0.03525096 0.02765264\n",
      "  0.09539477 0.09545446 0.1234462  0.17926176]\n",
      " [0.13945371 0.13313255 0.12685522 0.15835902 0.05838111 0.03116055\n",
      "  0.04992243 0.09208464 0.07093029 0.13972045]\n",
      " [0.08315614 0.0868597  0.1128277  0.24812688 0.03298173 0.01849896\n",
      "  0.09552673 0.11153788 0.06237936 0.14810483]\n",
      " [0.13306409 0.04670499 0.10607968 0.19398098 0.04821907 0.02400811\n",
      "  0.06236998 0.10224778 0.0519586  0.23136678]\n",
      " [0.1060425  0.06253972 0.13484797 0.09505878 0.05203251 0.02427617\n",
      "  0.07636451 0.08517829 0.0921124  0.27154717]\n",
      " [0.11065177 0.04840261 0.13458572 0.21009341 0.11528839 0.0279378\n",
      "  0.03987909 0.0647344  0.09246539 0.15596138]\n",
      " [0.12426403 0.05591971 0.14418025 0.21509472 0.03898505 0.03070511\n",
      "  0.0652661  0.11087745 0.07420254 0.14050505]\n",
      " [0.09523149 0.08997741 0.16876248 0.18792437 0.07560688 0.05098614\n",
      "  0.03417689 0.09578121 0.05808753 0.14346562]\n",
      " [0.1548525  0.07188135 0.16899477 0.12818843 0.03878304 0.03742016\n",
      "  0.05925892 0.08680051 0.12987512 0.12394521]\n",
      " [0.10691597 0.06791924 0.08311404 0.13367368 0.06026072 0.03305392\n",
      "  0.04582792 0.09536635 0.10232904 0.27153915]\n",
      " [0.07349973 0.06180052 0.19136986 0.19824195 0.06003935 0.03412817\n",
      "  0.09136272 0.07652569 0.08651018 0.1265219 ]\n",
      " [0.09862276 0.07832798 0.22579244 0.18194911 0.06579936 0.02482643\n",
      "  0.05967625 0.06421861 0.08021559 0.1205715 ]\n",
      " [0.12592912 0.06269827 0.12831806 0.16338144 0.04709684 0.0368975\n",
      "  0.08103456 0.11031187 0.08069252 0.1636398 ]\n",
      " [0.08710406 0.04154383 0.08814076 0.22806633 0.04506955 0.02004313\n",
      "  0.11474295 0.08536237 0.07840209 0.21152487]\n",
      " [0.07830651 0.04498235 0.15957923 0.28413224 0.04183002 0.03688669\n",
      "  0.05983172 0.06966925 0.09399805 0.13078399]\n",
      " [0.12062208 0.0663624  0.10794158 0.18667516 0.04524795 0.03077274\n",
      "  0.11062454 0.05133276 0.04057752 0.23984325]\n",
      " [0.10312713 0.06438669 0.1528882  0.19953129 0.0489968  0.03813025\n",
      "  0.05727739 0.11109094 0.07818066 0.1463907 ]\n",
      " [0.14076228 0.06904655 0.14583552 0.18042761 0.05578643 0.02584799\n",
      "  0.04625995 0.10101751 0.07978132 0.15523475]\n",
      " [0.13140173 0.0470777  0.11534545 0.3724408  0.03361032 0.02655545\n",
      "  0.06974776 0.040498   0.05035854 0.11296423]\n",
      " [0.14201388 0.0629822  0.10445953 0.24194132 0.04267445 0.03059569\n",
      "  0.05573577 0.08708116 0.06224719 0.17026874]\n",
      " [0.14872733 0.05900357 0.12449539 0.15655674 0.05485018 0.06467371\n",
      "  0.05698203 0.07183558 0.08383544 0.17904003]\n",
      " [0.09872053 0.06593619 0.1309389  0.15875496 0.05078008 0.05161526\n",
      "  0.08124709 0.07104001 0.07434644 0.2166206 ]\n",
      " [0.20086497 0.06825475 0.11459966 0.17200008 0.02776814 0.0146563\n",
      "  0.04823416 0.1115894  0.0574775  0.18455505]\n",
      " [0.11599836 0.05813123 0.11752125 0.1438378  0.05585558 0.04932549\n",
      "  0.11139058 0.02403757 0.10234396 0.22155824]\n",
      " [0.18650466 0.0609763  0.20361997 0.14224301 0.02793952 0.02689526\n",
      "  0.07901966 0.04772308 0.07175119 0.1533273 ]\n",
      " [0.17197889 0.0464542  0.1071483  0.230782   0.02444622 0.02277185\n",
      "  0.08283139 0.05415886 0.07094925 0.18847899]\n",
      " [0.22801808 0.03917002 0.10873941 0.15243144 0.04683957 0.03177353\n",
      "  0.08939739 0.08199553 0.08174235 0.1398927 ]\n",
      " [0.16709928 0.05607739 0.06985834 0.05439926 0.03176817 0.01371407\n",
      "  0.06551023 0.09079268 0.08398137 0.36679912]\n",
      " [0.08935622 0.04904708 0.15360826 0.26674592 0.02327608 0.01893577\n",
      "  0.0655264  0.08780337 0.09757331 0.14812759]\n",
      " [0.16302116 0.09116209 0.16638264 0.20046042 0.04726836 0.02040247\n",
      "  0.06469207 0.03101532 0.07128728 0.14430818]\n",
      " [0.06147441 0.13080122 0.20315707 0.16160232 0.05567637 0.03467233\n",
      "  0.07158995 0.08385258 0.06392953 0.13324423]\n",
      " [0.10417824 0.066578   0.1194642  0.09894713 0.02850292 0.03818117\n",
      "  0.0316792  0.05689609 0.06224028 0.39333284]\n",
      " [0.11995769 0.03598354 0.09830092 0.2038876  0.04662362 0.03072572\n",
      "  0.07567927 0.11670178 0.11287784 0.15926191]\n",
      " [0.05649148 0.06501928 0.05754262 0.17325523 0.04171875 0.0256923\n",
      "  0.07930531 0.0647618  0.0697593  0.3664539 ]\n",
      " [0.19047302 0.08555414 0.06864983 0.09127633 0.0535114  0.03534822\n",
      "  0.03667507 0.11075314 0.11177102 0.21598792]\n",
      " [0.10816237 0.07889441 0.17141572 0.15848449 0.07763077 0.03676595\n",
      "  0.05437314 0.07454315 0.06909117 0.17063889]\n",
      " [0.09503202 0.04513908 0.11312247 0.08733387 0.05827497 0.03772089\n",
      "  0.1198397  0.14341585 0.10108505 0.19903606]]\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'nothin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5f6f233d3eb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnothin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m             \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nothin' is not defined"
     ]
    }
   ],
   "source": [
    "num_steps = 5000\n",
    "# num_steps = 1 # TODO: remove\n",
    "summary_freq= 200\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "print('Initialized')\n",
    "\n",
    "mean_loss= 0\n",
    "train_accuracy= 0\n",
    "for step in range(num_steps):\n",
    "    # Get next batch of 100 images\n",
    "    batch_X, batch_y= mnist.train.next_batch(batch_size)\n",
    "    # The images returned by the function are formated in a matrix,\n",
    "    # where each row represents an image. Hence, we must reshape such\n",
    "    # matrix to convert the vector-representation of the images to \n",
    "    # standard 28 by 28 grey images.\n",
    "    batch_X = np.reshape(batch_X, [-1,28,28,1]) \n",
    "    # Construct Feed dictionary that consist of the input data \n",
    "    # that is going to be feed into the computation graph\n",
    "    feed_dict = {inputs : batch_X, labels : batch_y}\n",
    "    # Call the optimizer to perform one step of the training\n",
    "    _, l, train_pred = sess.run([optimizer, loss, yp],feed_dict=feed_dict)\n",
    "    \n",
    "    train_accuracy += accuracy(train_pred, batch_y)\n",
    "    mean_loss += l    \n",
    "    \n",
    "    if step%summary_freq == 0:\n",
    "        # obtain train accuracy\n",
    "        train_accuracy= train_accuracy/summary_freq\n",
    "        \n",
    "        # Evaluate the accuracy on a mini-batch of ~100 images\n",
    "        # extracted from the testing dataset\n",
    "        test_accuracy = 0\n",
    "        for i in range(100):\n",
    "            batch_X_test, batch_y_test= mnist.test.next_batch(batch_size) \n",
    "            batch_X_test = np.reshape(batch_X_test, [-1,28,28,1]) \n",
    "            pred = yp.eval(feed_dict={inputs: batch_X_test})\n",
    "            test_accuracy += accuracy(pred, batch_y_test)\n",
    "        test_accuracy = test_accuracy / 100\n",
    "        \n",
    "        # ------------------------------- #\n",
    "        print(step, ', train:',train_accuracy,' | test:', test_accuracy, ' | loss:', mean_loss/summary_freq)\n",
    "        mean_loss= 0\n",
    "        train_accuracy= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the trained model on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:  --- COMPLETE --- \n",
      "Prediction by the model:  --- COMPLETE --- \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8ebcc6efaa4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_sample_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    637\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 638\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Acquire one sample from the mnist dataset\n",
    "test_sample_x, test_sample_y= mnist.test.next_batch(1) \n",
    "\n",
    "''' ------- YOUR CODE HERE -------- '''\n",
    "# Evaluate the training model on test_sample_x\n",
    "# and compare it with the actual label test_sample_y\n",
    "pred = ''' --- COMPLETE --- '''\n",
    "print('Number:', ''' --- COMPLETE --- ''')\n",
    "print('Prediction by the model:', ''' --- COMPLETE --- ''')\n",
    "# ------------------------------- #\n",
    "\n",
    "# Plot\n",
    "plt.imshow(np.squeeze(test_sample_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
