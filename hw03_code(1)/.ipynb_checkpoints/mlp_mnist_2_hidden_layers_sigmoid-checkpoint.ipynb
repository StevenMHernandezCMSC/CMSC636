{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMSC 636, HW3: Multilayer perceptron on MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from types import SimpleNamespace\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load mnist dataset with labels encoded as one-hot vectors\n",
    "class Dataset():\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.index = 0\n",
    "        self.epochs = 0\n",
    "\n",
    "    def shuffle(self):\n",
    "        perm = np.arange(self.data[0].shape[0])\n",
    "        np.random.shuffle(perm)\n",
    "        self.data = tuple(datai[perm] for datai in self.data)\n",
    "    \n",
    "    def next_batch(self, batch_size):\n",
    "        start = self.index\n",
    "        end = self.index + batch_size\n",
    "        if end > self.data[0].shape[0]:\n",
    "            self.epochs += 1\n",
    "            self.shuffle()\n",
    "            self.index, start = 0, 0\n",
    "            end = batch_size\n",
    "        self.index = end\n",
    "        return tuple(datai[start:end, ...] for datai in self.data)\n",
    "            \n",
    "def load_mnist():\n",
    "    def preprocess(data, labels, num_classes):\n",
    "        # flatten images\n",
    "        data = data.astype(np.float32)/255.0\n",
    "        data = np.reshape(data, [data.shape[0], -1])\n",
    "        # one hot encoding\n",
    "        num_labels = labels.shape[0]\n",
    "        index_offset = np.arange(num_labels) * num_classes\n",
    "        labels_one_hot = np.zeros((num_labels, num_classes))\n",
    "        labels_one_hot.flat[index_offset + labels.ravel()] = 1\n",
    "        return data, labels_one_hot\n",
    "    train, test = tf.keras.datasets.mnist.load_data()\n",
    "    train = preprocess(train[0], train[1], 10)\n",
    "    test = preprocess(test[0], test[1], 10)\n",
    "    return SimpleNamespace(\n",
    "        train=Dataset(train), \n",
    "        test=Dataset(test))\n",
    "mnist = load_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size= 28*28\n",
    "n_outputs=  10\n",
    "n_hidden = 100\n",
    "batch_size= 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the computation graph. i.e:\n",
    "\n",
    "h1 = relu(x w1 + b1) </br> logits = h1 w2 + b2 </br>\n",
    "\n",
    "Where \"x w1\" is a matrix multiplication between the matices x and w1. The matrix x is a matrix whose rows represent the training input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define MLP\n",
    "w1 = tf.Variable(\n",
    "    tf.truncated_normal(\n",
    "        shape=[input_size, n_hidden],  # TODO\n",
    "        stddev=0.1), \n",
    "    name= 'w1')\n",
    "b1 = tf.Variable(\n",
    "    tf.truncated_normal(\n",
    "        shape=[n_hidden], \n",
    "        stddev=0.1), \n",
    "    name= 'b2') # TODO\n",
    "\n",
    "w2 = tf.Variable(\n",
    "    tf.truncated_normal(\n",
    "        shape=[n_hidden, n_outputs],  # TODO\n",
    "        stddev=0.1), \n",
    "    name= 'w1') # TODO\n",
    "b2 = tf.Variable(\n",
    "    tf.truncated_normal(\n",
    "        shape=[n_outputs], \n",
    "        stddev=0.1), \n",
    "    name= 'b2')\n",
    "\n",
    "# Define train setup\n",
    "inputs = tf.placeholder(tf.float32, [None, input_size])\n",
    "labels = tf.placeholder(tf.float32, [None, n_outputs])\n",
    "\n",
    "\n",
    "h1 = tf.nn.relu(tf.matmul(inputs, w1) + b1) # TODO\n",
    "logits = tf.matmul(h1, w2) + b2 # TODO\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    logits=logits, \n",
    "    labels=labels)) \n",
    "\n",
    "# Optimizer.\n",
    "optimizer = tf.train.AdamOptimizer(1e-3).minimize(loss) \n",
    "  \n",
    "# Predictions for the training, validation, and test data.\n",
    "yp = tf.nn.softmax(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "    if n_outputs == 1:\n",
    "        return (100.0 * np.sum(np.greater(predictions, 0.5) == np.greater(labels, 0.5))/ predictions.shape[0])\n",
    "    else:\n",
    "        return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/ predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "0 , train: 0.05  | test: 9.2  | loss: 0.012290966510772706\n",
      "200 , train: 82.26  | test: 86.9  | loss: 0.6576105801016092\n",
      "400 , train: 91.42  | test: 89.8  | loss: 0.3079544985294342\n",
      "600 , train: 93.195  | test: 91.3  | loss: 0.241419835165143\n",
      "800 , train: 94.44  | test: 92.9  | loss: 0.1947700461000204\n",
      "1000 , train: 95.0  | test: 97.1  | loss: 0.17838887935504316\n",
      "1200 , train: 95.505  | test: 95.5  | loss: 0.15944334097206592\n",
      "1400 , train: 96.055  | test: 98.4  | loss: 0.1398418141528964\n",
      "1600 , train: 96.32  | test: 98.5  | loss: 0.1289626108855009\n",
      "1800 , train: 96.655  | test: 96.6  | loss: 0.11749233668670059\n",
      "2000 , train: 97.065  | test: 97.4  | loss: 0.10536253722384573\n",
      "2200 , train: 97.105  | test: 96.1  | loss: 0.10039941374212503\n",
      "2400 , train: 97.34  | test: 97.1  | loss: 0.09337995091453194\n",
      "2600 , train: 97.695  | test: 97.0  | loss: 0.08210410128347576\n",
      "2800 , train: 97.565  | test: 96.8  | loss: 0.08425562762655318\n",
      "3000 , train: 97.755  | test: 96.8  | loss: 0.07813238651491701\n",
      "3200 , train: 98.06  | test: 97.7  | loss: 0.06661648285575211\n",
      "3400 , train: 97.985  | test: 97.7  | loss: 0.06959934249985963\n",
      "3600 , train: 98.16  | test: 96.7  | loss: 0.06521995353512466\n",
      "3800 , train: 98.565  | test: 97.4  | loss: 0.05636370628373697\n",
      "4000 , train: 98.275  | test: 97.1  | loss: 0.05913821845781058\n",
      "4200 , train: 98.395  | test: 98.0  | loss: 0.055289983730763194\n",
      "4400 , train: 98.695  | test: 97.9  | loss: 0.04715707353781909\n",
      "4600 , train: 98.545  | test: 98.2  | loss: 0.05079000615980476\n",
      "4800 , train: 98.6  | test: 97.3  | loss: 0.04933705968316644\n",
      "5000 , train: 98.885  | test: 97.5  | loss: 0.041768213547766206\n",
      "5200 , train: 98.845  | test: 97.8  | loss: 0.04062145226635039\n",
      "5400 , train: 98.765  | test: 97.9  | loss: 0.04213570861378685\n",
      "5600 , train: 99.16  | test: 97.6  | loss: 0.031386281908489765\n",
      "5800 , train: 98.93  | test: 97.6  | loss: 0.03729601305676624\n",
      "6000 , train: 98.945  | test: 97.5  | loss: 0.038536814893595873\n",
      "6200 , train: 99.195  | test: 97.6  | loss: 0.030094584960024803\n",
      "6400 , train: 99.075  | test: 97.2  | loss: 0.029753493795869872\n",
      "6600 , train: 99.16  | test: 97.8  | loss: 0.03103285339428112\n",
      "6800 , train: 99.45  | test: 97.5  | loss: 0.024075311303604394\n",
      "7000 , train: 99.2  | test: 98.6  | loss: 0.02973052865534555\n",
      "7200 , train: 99.385  | test: 98.3  | loss: 0.024691738283727317\n",
      "7400 , train: 99.535  | test: 97.6  | loss: 0.02070726495818235\n",
      "7600 , train: 99.385  | test: 97.5  | loss: 0.02262626089155674\n",
      "7800 , train: 99.27  | test: 97.4  | loss: 0.02538604297908023\n",
      "8000 , train: 99.525  | test: 97.5  | loss: 0.019490961313131265\n",
      "8200 , train: 99.64  | test: 97.2  | loss: 0.016685100102913564\n",
      "8400 , train: 99.48  | test: 97.5  | loss: 0.020151968230493367\n",
      "8600 , train: 99.61  | test: 99.1  | loss: 0.016164191956631838\n",
      "8800 , train: 99.665  | test: 98.2  | loss: 0.01582332328078337\n",
      "9000 , train: 99.575  | test: 97.7  | loss: 0.017489471852895802\n",
      "9200 , train: 99.66  | test: 98.3  | loss: 0.015218530556303449\n",
      "9400 , train: 99.705  | test: 97.9  | loss: 0.013442138804239221\n",
      "9600 , train: 99.71  | test: 98.2  | loss: 0.013594528697431087\n",
      "9800 , train: 99.795  | test: 98.4  | loss: 0.010422236272715964\n"
     ]
    }
   ],
   "source": [
    "num_steps = 10000\n",
    "summary_freq= 200\n",
    "n_test_logg= 10 # number of evaluations on test dataset (for logging information)\n",
    "\n",
    "tf.global_variables_initializer().run()\n",
    "print('Initialized')\n",
    "\n",
    "mean_loss= 0\n",
    "train_accuracy= 0\n",
    "# Perform num_steps training steps\n",
    "for step in range(num_steps):\n",
    "    # Get next batch of 100 images\n",
    "    batch_X, batch_y= mnist.train.next_batch(batch_size)    \n",
    "    # Construct Feed dictionary that consist of the input data \n",
    "    # that is going to be feed into the computation graph\n",
    "    feed_dict = {inputs : batch_X, labels : batch_y}\n",
    "    # Call the optimizer to perform one step of the training\n",
    "    _, l, train_pred = sess.run([optimizer, loss, yp],feed_dict=feed_dict)\n",
    "    \n",
    "    train_accuracy += accuracy(train_pred, batch_y)\n",
    "    mean_loss += l    \n",
    "    if step%summary_freq == 0:\n",
    "        # Obtain train accuracy\n",
    "        train_accuracy= train_accuracy/summary_freq\n",
    "        # Evaluate accuracy on test dataset\n",
    "        test_accuracy= 0\n",
    "        for i in range(n_test_logg):\n",
    "            batch_X_test, batch_y_test= mnist.test.next_batch(batch_size) \n",
    "            pred = yp.eval(feed_dict={inputs: batch_X_test})\n",
    "            test_accuracy += accuracy(pred, batch_y_test)\n",
    "        test_accuracy= test_accuracy/n_test_logg\n",
    "            \n",
    "        print(step, ', train:',train_accuracy,' | test:', test_accuracy, ' | loss:', mean_loss/summary_freq)\n",
    "        mean_loss= 0\n",
    "        train_accuracy= 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model using testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual number: 3\n",
      "Prediction by the model: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x10a239940>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Acquire one sample from the mnist dataset\n",
    "test_sample_x, test_sample_y= mnist.test.next_batch(1) \n",
    "\n",
    "# Get a prediction for this sample\n",
    "pred = yp.eval(feed_dict={inputs: test_sample_x})\n",
    "\n",
    "print('Actual number:', np.argmax(test_sample_y))\n",
    "print('Prediction by the model:', np.argmax(pred))\n",
    "\n",
    "# plot\n",
    "plt.imshow(np.reshape(test_sample_x, [28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
